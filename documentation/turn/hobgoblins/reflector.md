# Reflector Hobgoblin

## Purpose

The Reflector learns from turn outcomes and updates Si's knowledge systems. It transforms raw experience into refined knowledge that informs future decisions, enabling continuous improvement.

## Responsibilities

1. **Receive Assessment**: Accept outcome assessment from Evaluator
2. **Analyze Patterns**: Identify patterns in the outcome
3. **Extract Learning**: Determine what should be learned
4. **Update Knowledge**: Update consciousness, episodic memory, skills
5. **Adjust Confidence**: Refine confidence in learned patterns

## What Reflector Learns From

### Successful Outcomes
- What worked well?
- What patterns led to success?
- What should be reinforced?
- What confidence should increase?

### Failed Outcomes
- What went wrong?
- What patterns led to failure?
- What should be avoided?
- What confidence should decrease?

### Partial Outcomes
- What worked partially?
- What could be improved?
- What patterns are emerging?
- What needs refinement?

### User Feedback
- What did the user say?
- Was the user satisfied?
- What did the user appreciate?
- What did the user criticize?

## Decision Inputs

Reflector makes decisions using:

### Consciousness
- **Learning Policies**: What should be learned?
- **Governance**: What constraints apply to learning?
- **Values**: What matters in learning?

### Working Memory
- **Outcome Assessment**: What happened?
- **Turn Context**: What was the situation?
- **User Feedback**: What did the user say?

### Episodic Memory
- **Similar Outcomes**: What similar outcomes occurred?
- **Learned Patterns**: What patterns have been learned?
- **Confidence Levels**: How confident are we in patterns?
- **Learning History**: What has been learned before?

### Input
- **Outcome Assessment**: What is being learned from?
- **Feedback**: What additional information is available?

## Learning Process

```
Evaluator produces outcome assessment
    ↓
Reflector receives assessment
    ↓
Analyze outcome:
  - What was the goal?
  - What was expected?
  - What actually happened?
  - Did it match?
    ↓
Identify patterns:
  - What input patterns led to this outcome?
  - What decision patterns led to this outcome?
  - What execution patterns led to this outcome?
    ↓
Extract learning:
  - What should be remembered?
  - What patterns are important?
  - What should be reinforced or avoided?
    ↓
Update knowledge:
  - Update consciousness (mandates, values, governance)
  - Update episodic memory (store experience)
  - Update skills (refine patterns)
    ↓
Adjust confidence:
  - Increase confidence in successful patterns
  - Decrease confidence in failed patterns
  - Maintain confidence in neutral patterns
    ↓
Learning complete
```

## Types of Learning

### Pattern Learning
**What**: Identify patterns that predict outcomes
**Example**: "When I see financial keywords + user concern = high urgency is appropriate"
**Update**: Store in episodic memory as skill

### Outcome Learning
**What**: Remember what happened and why
**Example**: "Suspicious email scenario - high urgency worked well"
**Update**: Store in episodic memory as experience

### Mandate Learning
**What**: Refine consciousness mandates based on outcomes
**Example**: "Protecting user from financial harm is important"
**Update**: Reinforce in consciousness

### Governance Learning
**What**: Refine governance rules based on outcomes
**Example**: "Constraint checking prevented problems"
**Update**: Reinforce in consciousness governance

### Skill Learning
**What**: Develop new skills or refine existing ones
**Example**: "Improved ability to detect financial urgency"
**Update**: Add or refine skill in episodic memory

## Confidence Adjustment

Reflector adjusts confidence in learned patterns:

```
Pattern: "Financial keywords = high urgency"

Turn 1: Outcome GOOD
  → Confidence: 60% → 70%

Turn 2: Outcome GOOD
  → Confidence: 70% → 80%

Turn 3: Outcome GOOD
  → Confidence: 80% → 85%

Turn 4: Outcome BAD
  → Confidence: 85% → 75%

Turn 5: Outcome GOOD
  → Confidence: 75% → 80%
```

Over time, confidence converges toward actual pattern reliability.

## Learning Boundaries

Reflector respects learning boundaries:

### What Can Be Learned
- Patterns in decision-making
- Effectiveness of different approaches
- Relationships between inputs and outcomes
- Skill development

### What Cannot Be Learned (Requires Explicit Update)
- Core values and mandates (set by design)
- Fundamental governance rules (set by policy)
- Core identity (set by design)

Note: Consciousness CAN be updated through learning, but significant changes may require explicit review.

## Learning Example

**Scenario**: Suspicious email turn

**Turn 1:**
1. Router decides HIGH urgency
2. Responder sends immediate response
3. Executor researches in background
4. Evaluator assesses: User stopped, research succeeded → GOOD
5. Reflector learns:
   - Pattern: "Financial keywords + user concern = high urgency"
   - Outcome: "Immediate response prevented bad action"
   - Confidence: 60% (first occurrence)
   - Update: Store in episodic memory

**Turn 2 (similar situation):**
1. Router sees similar situation → uses learned pattern
2. Decides HIGH urgency (better informed)
3. Responder sends immediate response
4. Executor researches in background
5. Evaluator assesses: User stopped, research succeeded → GOOD
6. Reflector learns:
   - Pattern confirmed
   - Confidence: 70% (second success)
   - Update: Increase confidence

**Turn 3 (different situation):**
1. Router sees "I'm curious about my credit score"
2. Decides LOW urgency (learned distinction)
3. Plan Generator creates research plan
4. Executor researches thoroughly
5. Evaluator assesses: User got comprehensive answer → GOOD
6. Reflector learns:
   - Refined pattern: "Not all credit-related queries need urgency"
   - Confidence: 65% (new pattern)
   - Update: Store refined pattern

Over time, Router's decisions become more nuanced and effective.

## Learning Velocity

Learning speed depends on:

### Frequency
- How often does Si encounter similar situations?
- High frequency → fast learning
- Low frequency → slow learning

### Clarity
- How clear is the feedback signal?
- Clear feedback → fast learning
- Ambiguous feedback → slow learning

### Relevance
- How directly does feedback relate to decision?
- Direct relevance → fast learning
- Indirect relevance → slow learning

## Key Principle

**Reflector enables continuous improvement.** By learning from experience, Reflector ensures that Si's decisions improve over time. The system doesn't need perfect rules upfront - it learns from experience and adapts.

