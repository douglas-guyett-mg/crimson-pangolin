# Learning Loop: Continuous Improvement Through Experience

## Overview

The learning loop is the mechanism by which Si improves its decision-making over time. It transforms raw experience into refined knowledge that informs future decisions.

## The Loop

```
1. Hobgoblin Makes Decision
   (using consciousness + working memory + episodic memory + input)
        ↓
2. Turn Executes
   (decision is acted upon)
        ↓
3. Evaluator Assesses Outcome
   (was the decision good? did it achieve the goal?)
        ↓
4. Reflector Learns
   (what patterns led to this outcome? what should we remember?)
        ↓
5. Learning Updates Knowledge
   (consciousness, episodic memory, skills are refined)
        ↓
6. Next Turn
   (hobgoblin sees similar situation and makes better decision)
```

## Detailed Steps

### Step 1: Hobgoblin Makes Decision

A hobgoblin needs to make a decision. It gathers information from:
- Consciousness (values, mandates, governance)
- Working Memory (current context)
- Episodic Memory (previous experiences)
- Input (the question or situation)

It makes the best decision it can with available information.

**Example**: Router decides urgency level is HIGH based on financial keywords and mandate about protecting user from harm.

### Step 2: Turn Executes

The decision is acted upon. Hobgoblins coordinate, tools are called, responses are generated.

**Example**: Responder generates immediate response, Executor starts research in background.

### Step 3: Evaluator Assesses Outcome

After the turn completes (or at key checkpoints), Evaluator asks:
- Did the decision achieve its goal?
- Were there unintended consequences?
- What was the user's reaction?
- Did the outcome match expectations?

Evaluator produces an **outcome assessment** that captures:
- What was the decision?
- What was the expected outcome?
- What was the actual outcome?
- Did it match? Why or why not?

**Example**: Evaluator checks:
- Expected: User stops and waits for verification
- Actual: User stopped and waited
- Match: YES ✓
- Reasoning: Immediate response was appropriate for urgency level

### Step 4: Reflector Learns

Reflector analyzes the outcome assessment and extracts learnings:

**Pattern Recognition**: What patterns in the input led to this outcome?
- "When I see financial keywords + user concern + first message → high urgency is appropriate"

**Skill Development**: What capability did Si develop or refine?
- "Improved ability to detect financial urgency"

**Knowledge Updates**: What should be remembered for future decisions?
- "This pattern worked well; similar situations should follow this approach"

**Confidence Adjustment**: How confident should Si be in similar decisions?
- "Increase confidence in financial urgency detection"

### Step 5: Learning Updates Knowledge

Reflector updates Si's knowledge base:

**Consciousness Updates**:
- Reinforce mandates that proved effective
- Refine governance rules if needed
- Update capabilities catalog if new capabilities were discovered

**Episodic Memory Updates**:
- Store the experience with outcome
- Tag with relevant patterns and contexts
- Link to related experiences

**Skills Updates**:
- Add or refine skills based on what worked
- Increase confidence in proven patterns
- Decrease confidence in patterns that didn't work

**Example**: 
- Consciousness: Reinforce "Protect user from financial harm" mandate
- Episodic Memory: Store "Suspicious email scenario - high urgency worked well"
- Skills: Refine "Financial urgency detection" skill with new pattern

### Step 6: Next Turn

When a similar situation arises, the hobgoblin has better information:
- Consciousness is clearer about priorities
- Episodic Memory has relevant experiences
- Skills are more refined

The decision is better informed and more likely to succeed.

## What Gets Learned?

The learning loop can improve:

### Router's Decisions
- Better urgency detection
- Better hobgoblin activation patterns
- Better routing strategies

### Plan Generator's Decisions
- Better plan structures
- Better step sequencing
- Better resource allocation

### Executor's Decisions
- Better tool selection
- Better tool ordering
- Better error recovery

### All Hobgoblins
- Better decision-making in their domain
- Better pattern recognition
- Better outcome prediction

## Learning Boundaries

The learning loop operates within constraints:

**What can be learned**:
- Patterns in decision-making
- Effectiveness of different approaches
- Relationships between inputs and outcomes
- Skill development

**What cannot be learned** (requires consciousness update):
- Core values and mandates (these are set by design)
- Governance rules (these are set by policy)
- Fundamental identity (this is set by design)

Note: Consciousness CAN be updated through the learning loop, but this is a significant change that may require explicit review.

## Feedback Sources

The learning loop uses multiple feedback sources:

### Explicit Feedback
- User satisfaction signals
- User corrections ("No, that's wrong")
- User praise ("That was helpful")

### Implicit Feedback
- Outcome success/failure
- Time to resolution
- Resource usage
- Error rates

### Contextual Feedback
- Conversation continuation (user keeps talking = engaged)
- Conversation termination (user stops = satisfied or frustrated)
- Follow-up questions (user asks more = needs clarification)

## Learning Velocity

Learning speed depends on:
- **Frequency**: How often does Si encounter similar situations?
- **Clarity**: How clear is the feedback signal?
- **Relevance**: How directly does the feedback relate to the decision?

High-frequency, clear, relevant feedback → fast learning
Low-frequency, ambiguous, indirect feedback → slow learning

## Example: Full Learning Loop

**Turn 1:**
1. Router sees "suspicious email from bank" → decides HIGH urgency
2. Responder sends immediate response
3. Executor researches in background
4. Evaluator assesses: User stopped, research succeeded → GOOD outcome
5. Reflector learns: "Financial keywords + user concern = high urgency works"
6. Updates: Consciousness reinforced, episodic memory stored, skill refined

**Turn 2 (similar situation):**
1. Router sees "weird message from credit card company" → decides HIGH urgency (better informed)
2. Responder sends immediate response
3. Executor researches in background
4. Evaluator assesses: User stopped, research succeeded → GOOD outcome
5. Reflector learns: "Pattern confirmed; confidence increased"
6. Updates: Skill confidence increased

**Turn 3 (different situation):**
1. Router sees "I'm curious about my credit score" → decides LOW urgency (learned distinction)
2. Plan Generator creates research plan
3. Executor researches thoroughly
4. Evaluator assesses: User got comprehensive answer → GOOD outcome
5. Reflector learns: "Not all credit-related queries need urgency"
6. Updates: Refined pattern recognition

Over time, Router's decisions become more nuanced and effective.

